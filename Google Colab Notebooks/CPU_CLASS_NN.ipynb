{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyONmoVLYaY9sCbFbM6pXH5x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YToQRRMGtWLR","executionInfo":{"status":"ok","timestamp":1706607185352,"user_tz":-330,"elapsed":88549,"user":{"displayName":"Akshay De Silva","userId":"17011296734322391564"}},"outputId":"623d5bc0-6f2e-4ce3-fc4d-036a75744054"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","1875/1875 - 16s - loss: 0.2560 - accuracy: 0.9269 - 16s/epoch - 8ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Epoch 1/5 - CPU Usage: 92.9%, F1 Score: 0.9591\n","1875/1875 - 5s - loss: 0.1155 - accuracy: 0.9662 - 5s/epoch - 3ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Epoch 2/5 - CPU Usage: 38.8%, F1 Score: 0.9699\n","1875/1875 - 5s - loss: 0.0800 - accuracy: 0.9761 - 5s/epoch - 3ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Epoch 3/5 - CPU Usage: 2.5%, F1 Score: 0.9771\n","1875/1875 - 5s - loss: 0.0607 - accuracy: 0.9811 - 5s/epoch - 3ms/step\n","313/313 [==============================] - 1s 2ms/step\n","Epoch 4/5 - CPU Usage: 2.0%, F1 Score: 0.9778\n","1875/1875 - 6s - loss: 0.0479 - accuracy: 0.9854 - 6s/epoch - 3ms/step\n","313/313 [==============================] - 1s 3ms/step\n","Epoch 5/5 - CPU Usage: 3.5%, F1 Score: 0.9782\n","Average CPU Usage: 27.939999999999998%, Average F1 Score: 0.9724\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import time\n","import psutil\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# neural network model\n","model = models.Sequential([\n","    layers.Flatten(input_shape=(28, 28)),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Load dataset (MNIST)\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","\n","num_epochs = 5\n","check_interval = 1\n","total_cpu_usage = 0\n","total_f1 = 0\n","num_checks = 0\n","\n","for epoch in range(num_epochs):\n","    start_time = time.time()\n","\n","    cpu_percent = psutil.cpu_percent(interval=1)\n","    model.fit(x_train, y_train, epochs=1, verbose=2)\n","\n","    y_pred = model.predict(x_test)\n","    y_pred_classes = tf.argmax(y_pred, axis=1).numpy()\n","\n","    precision = precision_score(y_test, y_pred_classes, average='weighted')\n","    recall = recall_score(y_test, y_pred_classes, average='weighted')\n","    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n","\n","    end_time = time.time()\n","\n","    total_cpu_usage += cpu_percent\n","    total_f1 += f1\n","    num_checks += 1\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs} - CPU Usage: {cpu_percent}%, F1 Score: {f1:.4f}\")\n","\n","    time.sleep(5)\n","\n","average_cpu_usage = total_cpu_usage / num_checks\n","average_f1 = total_f1 / num_checks\n","print(f\"Average CPU Usage: {average_cpu_usage}%, Average F1 Score: {round(average_f1, 4)}\")\n"]}]}