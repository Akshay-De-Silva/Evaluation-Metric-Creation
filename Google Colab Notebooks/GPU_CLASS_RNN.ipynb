{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMd13E5hD5gvHZyoUlWaTcv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05fzqkcueVzV","executionInfo":{"status":"ok","timestamp":1706536279534,"user_tz":-330,"elapsed":144981,"user":{"displayName":"Akshay De Silva","userId":"17011296734322391564"}},"outputId":"8ef97169-d379-4406-d9fd-1f064315cbc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n","1 Physical GPUs, 1 Logical GPUs\n","1875/1875 - 16s - loss: 0.4314 - accuracy: 0.8634 - 16s/epoch - 9ms/step\n","313/313 [==============================] - 2s 4ms/step\n","RNN Model, Epoch 1/5 - Precision: 0.9454, Recall: 0.9442, F1 Score: 0.9443\n","VRAM Usage: 639 MiB\n","1875/1875 - 16s - loss: 0.1993 - accuracy: 0.9422 - 16s/epoch - 8ms/step\n","313/313 [==============================] - 2s 4ms/step\n","RNN Model, Epoch 2/5 - Precision: 0.9562, Recall: 0.9552, F1 Score: 0.9552\n","VRAM Usage: 1151 MiB\n","1875/1875 - 17s - loss: 0.1666 - accuracy: 0.9531 - 17s/epoch - 9ms/step\n","313/313 [==============================] - 1s 4ms/step\n","RNN Model, Epoch 3/5 - Precision: 0.9522, Recall: 0.9506, F1 Score: 0.9508\n","VRAM Usage: 1151 MiB\n","1875/1875 - 15s - loss: 0.1486 - accuracy: 0.9573 - 15s/epoch - 8ms/step\n","313/313 [==============================] - 2s 7ms/step\n","RNN Model, Epoch 4/5 - Precision: 0.9657, Recall: 0.9654, F1 Score: 0.9654\n","VRAM Usage: 1151 MiB\n","1875/1875 - 15s - loss: 0.1337 - accuracy: 0.9623 - 15s/epoch - 8ms/step\n","313/313 [==============================] - 1s 4ms/step\n","RNN Model, Epoch 5/5 - Precision: 0.9653, Recall: 0.9649, F1 Score: 0.9649\n","VRAM Usage: 1151 MiB\n","Average VRAM Usage: 1048.6 MiB\n","Average F1 Score: 0.96\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import time\n","\n","# Load a dummy dataset (MNIST)\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","# Configure TensorFlow to allocate GPU memory on an as-needed basis\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Set memory growth for each GPU\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        print(e)\n","\n","# Training loop with GPU VRAM tracking for the RNN model\n","rnn_model = models.Sequential([\n","    layers.SimpleRNN(128, activation='relu', input_shape=(28, 28)),\n","    layers.Flatten(),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","total_vram_usage = 0\n","total_f1 = 0\n","num_checks = 5\n","\n","# Train the RNN model\n","for epoch in range(num_checks):\n","    start_time = time.time()\n","\n","    with tf.device('/GPU:0'):\n","        rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","        rnn_model.fit(x_train, y_train, epochs=1, verbose=2)\n","\n","        # Predict on the test set\n","        y_pred = rnn_model.predict(x_test)\n","        y_pred_classes = tf.argmax(y_pred, axis=1).numpy()\n","\n","        # Calculate precision, recall, and F1 score\n","        precision = precision_score(y_test, y_pred_classes, average='weighted')\n","        recall = recall_score(y_test, y_pred_classes, average='weighted')\n","        f1 = f1_score(y_test, y_pred_classes, average='weighted')\n","\n","        # Print information\n","        print(f\"RNN Model, Epoch {epoch + 1}/5 - Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n","\n","    end_time = time.time()\n","\n","    # Check GPU usage and extract VRAM usage\n","    gpu_info = !nvidia-smi\n","    vram_usage_line = next((line for line in gpu_info if 'MiB /' in line), None)\n","\n","    if vram_usage_line:\n","        # Extract numerical parts and convert to integers\n","        vram_used_str = vram_usage_line.split()[8]\n","        vram_used = int(vram_used_str[:-3])  # Remove 'MiB' and convert to int\n","\n","        # Print VRAM usage information\n","        print(f\"VRAM Usage: {vram_used} MiB\")\n","\n","        total_vram_usage += vram_used\n","        total_f1 += f1\n","\n","        # Optional: Add a delay to avoid overwhelming the GPU monitoring tool\n","        time.sleep(5)\n","\n","# Calculate and print average VRAM usage\n","average_vram_usage = total_vram_usage / num_checks\n","average_f1 = total_f1 / num_checks\n","print(f\"Average VRAM Usage: {average_vram_usage} MiB\")\n","print(f\"Average F1 Score: {round(average_f1, 2)}\")\n","\n"]}]}