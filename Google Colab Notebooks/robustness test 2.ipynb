{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOpTlgQ6A1sAY20UBQj/Vxx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn import datasets"],"metadata":{"id":"7tNuuRbT2m5Z","executionInfo":{"status":"ok","timestamp":1712146028879,"user_tz":-330,"elapsed":379,"user":{"displayName":"Akshay De Silva","userId":"17011296734322391564"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","\n","def add_noise(data, target, noise_pct):\n","  num_samples = len(data)\n","  num_noise = int(noise_pct * num_samples)\n","  noise_indices = np.random.choice(num_samples, num_noise, replace=False)\n","  data[noise_indices] = np.random.rand(num_noise, data.shape[1])\n","  return data, target\n","\n","def iris_logistic_regression(noise_pct=0):\n","  iris = load_iris()\n","  X, y = iris.data, iris.target\n","\n","  # Add noise to data\n","  if noise_pct > 0:\n","    X, y = add_noise(X.copy(), y.copy(), noise_pct)\n","\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","  from sklearn.svm import SVC\n","  model = SVC()\n","  model.fit(X_train, y_train)\n","\n","  predictions = model.predict(X_test)\n","\n","  f1 = f1_score(y_test, predictions, average='weighted')\n","\n","  return f1\n","\n","noise_level = 0.25\n","f1 = iris_logistic_regression(noise_level)\n","print(f\"F1 score with {noise_level*100}% noise:\", f1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wIy67RdVJ1z","executionInfo":{"status":"ok","timestamp":1712146030879,"user_tz":-330,"elapsed":481,"user":{"displayName":"Akshay De Silva","userId":"17011296734322391564"}},"outputId":"80cfaf8f-8dc2-462f-f611-d1fd6616dd72"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 score with 25.0% noise: 0.7720987654320989\n"]}]},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score\n","\n","def add_noise(data, target, noise_pct):\n","  num_samples = len(data)\n","  num_noise = int(noise_pct * num_samples)\n","  noise_indices = np.random.choice(num_samples, num_noise, replace=False)\n","  data[noise_indices] = np.random.rand(num_noise, data.shape[1])\n","  return data, target\n","\n","def iris_linear_regression(noise_pct=0):\n","  iris = load_iris()\n","  X, y = iris.data, iris.target\n","\n","  # Add noise to data\n","  if noise_pct > 0:\n","    X, y = add_noise(X.copy(), y.copy(), noise_pct)\n","\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","  from sklearn.linear_model import ElasticNet\n","\n","  model = ElasticNet()\n","  model.fit(X_train, y_train)\n","\n","  predictions = model.predict(X_test)\n","\n","  r2 = r2_score(y_test, predictions)\n","\n","  return r2\n","\n","noise_0 = 0\n","noise_25 = 0.25\n","noise_50 = 0.50\n","noise_75 = 0.75\n","\n","r2 = iris_linear_regression(noise_0)\n","print(f\"R-squared score with {noise_level*100}% noise:\", r2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JMFaOcx8avP_","executionInfo":{"status":"ok","timestamp":1712146060006,"user_tz":-330,"elapsed":377,"user":{"displayName":"Akshay De Silva","userId":"17011296734322391564"}},"outputId":"787ce9f4-9312-4836-c336-4ec66a0daaff"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["R-squared score with 25.0% noise: 0.7083498212185959\n"]}]}]}