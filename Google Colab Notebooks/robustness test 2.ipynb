{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOjD//FAFAHzpunh8r7ZX8F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"7YsSOXmOT9xU","executionInfo":{"status":"error","timestamp":1710761470575,"user_tz":-330,"elapsed":530,"user":{"displayName":"Akshay De Silva","userId":"17011296734322391564"}},"outputId":"dfe4f370-5bef-4bb7-c6ee-08044549699b"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Columns must be same length as key","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-bc1403fd20e9>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mnoise_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m  \u001b[0;31m# Add 20% noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"F1 score with {noise_level*100}% noise:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-bc1403fd20e9>\u001b[0m in \u001b[0;36miris_logistic_regression\u001b[0;34m(noise_pct)\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;31m# Add noise to data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnoise_pct\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_pct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Split data into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-bc1403fd20e9>\u001b[0m in \u001b[0;36madd_noise\u001b[0;34m(data, target, noise_pct)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mnum_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_pct\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mnoise_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3966\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3967\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3968\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3969\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3970\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4018\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4019\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iset_not_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4021\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_iset_not_inplace\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4045\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4046\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4048\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"]}],"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n","import time\n","import psutil\n","import numpy as np\n","from sklearn import datasets\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","def add_noise(data, target, noise_pct):\n","  \"\"\"\n","  Adds random noise to the data based on a percentage.\n","\n","  Args:\n","      data: The data to add noise to.\n","      target: The target labels for the data.\n","      noise_pct: The percentage of data to corrupt with noise (0 to 1).\n","\n","  Returns:\n","      A tuple containing the data with noise and the target labels.\n","  \"\"\"\n","  num_samples = len(data)\n","  num_noise = int(noise_pct * num_samples)\n","  noise_indices = np.random.choice(num_samples, num_noise, replace=False)\n","  data[noise_indices] = np.random.rand(num_noise, data.shape[1])\n","  return data, target\n","\n","def iris_logistic_regression(noise_pct=0):\n","  classDataset = \"https://raw.githubusercontent.com/Akshay-De-Silva/ml_apis/main/stroke.csv\"\n","\n","  df = pd.read_csv(classDataset)\n","  features = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level']\n","  target = 'stroke'\n","\n","  X = df[features]\n","  y = df[target]\n","\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","  # Add noise to data\n","  if noise_pct > 0:\n","    X, y = add_noise(X.copy(), y.copy(), noise_pct)\n","\n","  # Split data into training and testing sets\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","  # Train the logistic regression model\n","  model = LogisticRegression(solver='liblinear')\n","  model.fit(X_train, y_train)\n","\n","  # Make predictions on the test set\n","  predictions = model.predict(X_test)\n","\n","  # Calculate F1 score\n","  f1 = f1_score(y_test, predictions, average='weighted')\n","\n","  return f1\n","\n","# Example usage\n","noise_level = 0.2  # Add 20% noise\n","f1 = iris_logistic_regression(noise_level)\n","print(f\"F1 score with {noise_level*100}% noise:\", f1)\n"]},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","\n","def add_noise(data, target, noise_pct):\n","  \"\"\"\n","  Adds random noise to the data based on a percentage.\n","\n","  Args:\n","      data: The data to add noise to.\n","      target: The target labels for the data.\n","      noise_pct: The percentage of data to corrupt with noise (0 to 1).\n","\n","  Returns:\n","      A tuple containing the data with noise and the target labels.\n","  \"\"\"\n","  num_samples = len(data)\n","  num_noise = int(noise_pct * num_samples)\n","  noise_indices = np.random.choice(num_samples, num_noise, replace=False)\n","  data[noise_indices] = np.random.rand(num_noise, data.shape[1])\n","  return data, target\n","\n","def iris_logistic_regression(noise_pct=0):\n","  \"\"\"\n","  Loads the iris dataset, adds noise, trains a logistic regression model,\n","  and returns the F1 score.\n","\n","  Args:\n","      noise_pct: The percentage of data to corrupt with noise (0 to 1).\n","\n","  Returns:\n","      The F1 score of the logistic regression model.\n","  \"\"\"\n","  iris = load_iris()\n","  X, y = iris.data, iris.target\n","\n","  # Add noise to data\n","  if noise_pct > 0:\n","    X, y = add_noise(X.copy(), y.copy(), noise_pct)\n","\n","  # Split data into training and testing sets\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","  # Train the logistic regression model\n","  from sklearn.svm import SVC\n","  model = SVC()\n","  model.fit(X_train, y_train)\n","\n","  # Make predictions on the test set\n","  predictions = model.predict(X_test)\n","\n","  # Calculate F1 score\n","  f1 = f1_score(y_test, predictions, average='weighted')\n","\n","  return f1\n","\n","# Example usage\n","noise_level = 0.75  # Add 20% noise\n","f1 = iris_logistic_regression(noise_level)\n","print(f\"F1 score with {noise_level*100}% noise:\", f1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wIy67RdVJ1z","executionInfo":{"status":"ok","timestamp":1710762923455,"user_tz":-330,"elapsed":3,"user":{"displayName":"Akshay De Silva","userId":"17011296734322391564"}},"outputId":"c9bf3aed-6078-4e67-a4eb-b0dcf08a93fd"},"execution_count":142,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 score with 75.0% noise: 0.47455026455026456\n"]}]},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score\n","\n","def add_noise(data, target, noise_pct):\n","  \"\"\"\n","  Adds random noise to the data based on a percentage.\n","\n","  Args:\n","      data: The data to add noise to.\n","      target: The target labels for the data.\n","      noise_pct: The percentage of data to corrupt with noise (0 to 1).\n","\n","  Returns:\n","      A tuple containing the data with noise and the target labels.\n","  \"\"\"\n","  num_samples = len(data)\n","  num_noise = int(noise_pct * num_samples)\n","  noise_indices = np.random.choice(num_samples, num_noise, replace=False)\n","  data[noise_indices] = np.random.rand(num_noise, data.shape[1])\n","  return data, target\n","\n","def iris_linear_regression(noise_pct=0):\n","  \"\"\"\n","  Loads the iris dataset, adds noise, trains a linear regression model,\n","  and returns the R-squared score.\n","\n","  Args:\n","      noise_pct: The percentage of data to corrupt with noise (0 to 1).\n","\n","  Returns:\n","      The R-squared score of the linear regression model.\n","  \"\"\"\n","  iris = load_iris()\n","  X, y = iris.data, iris.target\n","\n","  # Add noise to data\n","  if noise_pct > 0:\n","    X, y = add_noise(X.copy(), y.copy(), noise_pct)\n","\n","  # Split data into training and testing sets\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","  from sklearn.linear_model import ElasticNet\n","\n","  model = ElasticNet()\n","  model.fit(X_train, y_train)\n","\n","  # Make predictions on the test set\n","  predictions = model.predict(X_test)\n","\n","  # Calculate R-squared score\n","  r2 = r2_score(y_test, predictions)\n","\n","  return r2\n","\n","# Example usage\n","noise_0 = 0\n","noise_25 = 0.25\n","noise_50 = 0.50\n","noise_75 = 0.75\n","\n","r2 = iris_linear_regression(noise_50)\n","print(f\"R-squared score with {noise_level*100}% noise:\", r2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JMFaOcx8avP_","executionInfo":{"status":"ok","timestamp":1710763710614,"user_tz":-330,"elapsed":3,"user":{"displayName":"Akshay De Silva","userId":"17011296734322391564"}},"outputId":"3284a460-06e0-4b1b-9883-4ea7f2f6e121"},"execution_count":234,"outputs":[{"output_type":"stream","name":"stdout","text":["R-squared score with 25.0% noise: -0.07298789631477431\n"]}]}]}