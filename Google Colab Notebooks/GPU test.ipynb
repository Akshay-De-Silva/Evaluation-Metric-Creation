{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMOLfkzzWGDKehf7Jj5uy4t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import time\n","\n","# Check GPU availability\n","!nvidia-smi\n","\n","# Create a simple neural network model\n","model = models.Sequential([\n","    layers.Flatten(input_shape=(28, 28)),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Load a dummy dataset (MNIST)\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","# Configure TensorFlow to allocate GPU memory on an as-needed basis\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Set memory growth for each GPU\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        print(e)\n","\n","# Training loop with GPU VRAM tracking\n","num_epochs = 5\n","check_interval = 1\n","total_vram_usage = 0  # To accumulate total VRAM usage\n","num_checks = 0  # To count the number of checks\n","\n","for epoch in range(num_epochs):\n","    # Train the model\n","    start_time = time.time()\n","\n","    # Track VRAM usage during training\n","    with tf.device('/GPU:0'):\n","        model.fit(x_train, y_train, epochs=1, verbose=2)\n","\n","    end_time = time.time()\n","\n","    # Check GPU usage and extract VRAM usage\n","    gpu_info = !nvidia-smi\n","    vram_usage_line = next((line for line in gpu_info if 'MiB /' in line), None)\n","\n","    if vram_usage_line:\n","        # Extract numerical parts and convert to integers\n","        vram_used_str = vram_usage_line.split()[8]\n","        vram_used = int(vram_used_str[:-3])  # Remove 'MiB' and convert to int\n","\n","        # Accumulate VRAM usage\n","        total_vram_usage += vram_used\n","        num_checks += 1\n","\n","        # Print information\n","        print(f\"Epoch {epoch + 1}/{num_epochs} - VRAM Usage: {vram_used} MiB\")\n","\n","        # Optional: Add a delay to avoid overwhelming the GPU monitoring tool\n","        time.sleep(5)\n","\n","# Calculate and print average VRAM usage\n","average_vram_usage = total_vram_usage / num_checks\n","print(f\"Average VRAM Usage: {average_vram_usage} MiB\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EDYscBGQmPPQ","executionInfo":{"status":"ok","timestamp":1706438179344,"user_tz":-330,"elapsed":63510,"user":{"displayName":"Akshay De Silva","userId":"17011296734322391564"}},"outputId":"adf7f6c8-a039-4439-9e32-515be3246e0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jan 28 10:35:20 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","Physical devices cannot be modified after being initialized\n","1875/1875 - 9s - loss: 0.2567 - accuracy: 0.9267 - 9s/epoch - 5ms/step\n","Epoch 1/5 - VRAM Usage: 639 MiB\n","1875/1875 - 4s - loss: 0.1139 - accuracy: 0.9668 - 4s/epoch - 2ms/step\n","Epoch 2/5 - VRAM Usage: 1151 MiB\n","1875/1875 - 5s - loss: 0.0785 - accuracy: 0.9767 - 5s/epoch - 3ms/step\n","Epoch 3/5 - VRAM Usage: 1151 MiB\n","1875/1875 - 4s - loss: 0.0588 - accuracy: 0.9819 - 4s/epoch - 2ms/step\n","Epoch 4/5 - VRAM Usage: 1151 MiB\n","1875/1875 - 4s - loss: 0.0460 - accuracy: 0.9856 - 4s/epoch - 2ms/step\n","Epoch 5/5 - VRAM Usage: 2175 MiB\n","Average VRAM Usage: 1253.4 MiB\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Y8ho0yaJIrFw"},"execution_count":null,"outputs":[]}]}